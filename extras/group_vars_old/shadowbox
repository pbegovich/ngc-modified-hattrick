domain: shadowbox.lab
dns_server_local: 192.168.0.4
dns_server_public: 1.1.1.1
use_public_dns: false #Default to false (set true individually on kvm and idm)

git_repo: https://github.com/redhat-kejones/hattrick

register_rhn: true
rhn_user: "{{ vault_rhn_user }}"
rhn_pwd: "{{ vault_rhn_pwd }}"
rhn_pool_name: "{{ vault_rhn_pool_name }}"

#MPC Synology
local_repo_url: "http://192.168.0.8/"

networks:
  external:
    name: external
    cidr: 192.168.0.0/23
    defroute: true
    gateway: 192.168.0.1
    vlan: 1
    fipStart: 192.168.1.70
    fipEnd: 192.168.1.199
  provisioning:
    name: provisioning
    cidr: 192.168.2.0/24
    defroute: false
    vlan: 2

versions:
  rhosp: 10
  satellite: 6.3
  ocp: 3.6
  cfme: 5.9

rhel_idm:
  hostname_short: idm
  realm: "{{ domain | upper }}"
  dm_pwd: "{{ vault_idm_dm_pwd }}"
  admin_pwd: "{{ vault_idm_admin_pwd }}"
  forward_ip: "{{ dns_server_public }}"
  reverse_zone: "168.192.in-addr.arpa."
  repos:
    - rhel-7-server-rpms
    - rhel-7-server-extras-rpms
  packages:
    - ipa-server
    - ipa-server-dns
  users:
  - username: operator
    password: redhat
    display_name: "Shadowbox Operator"
    first_name: Shadowbox
    last_name: Operator
    email: "shadowbox@redhat.com"
    phone: "+18887334281"
    title: "Shadowbox Operator"
  dns_records:
  - hostname: router
    record_type: A
    ip_address: 192.168.0.1
    reverse_record: 1.0
  - hostname: switch
    record_type: A
    ip_address: 192.168.0.2
    reverse_record: 2.0
  - hostname: kvm
    record_type: A
    ip_address: 192.168.0.3
    reverse_record: 3.0
  - hostname: undercloud
    record_type: A
    ip_address: 192.168.0.5
    reverse_record: 5.2
  - hostname: openstack
    record_type: A
    ip_address: 192.168.1.40
    reverse_record: 40.1

rhel_kvm:
  hostname_full: "kvm.{{ domain }}"
  disks:
    root: sda
  repos:
    - rhel-7-server-rpms
    - rhel-7-server-extras-rpms
    - rhel-7-server-rh-common-rpms
  packages:
    - 'screen'
    - 'wget'
    - 'vim'
    - 'tree'
    - 'yum-utils'
    - 'git'
    - 'qemu-kvm'
    - 'qemu-img'
    - 'libvirt'
    - 'virt-install'
    - 'libvirt-client'
    - 'libvirt-python'
    - 'libguestfs-tools-c'
    - 'rhel-guest-image-7'
    - 'ansible'
    - 'gcc'
    - 'gcc-c++'
    - 'libffi-devel'
    - 'openssl-devel'
    - 'python'
    - 'python-devel'
    - 'python-virtualenv'

vmenator:
  vms:
  - name: undercloud
    disk_os_name: undercloud-os.qcow2
    disk_os_size: 80G
    nics:
    - name: eth0
      config: "--type bridge --source br2 --model virtio"
    - name: eth1
      config: "--type bridge --source br1 --model virtio"
    ram: 16384
    vcpus: 8
  - name: idm
    disk_os_name: idm-os.qcow2
    disk_os_size: 80G
    nics:
    - name: eth0
      config: "--type bridge --source br1 --model virtio"
    ram: 4096
    vcpus: 1
  - name: repo
    disk_os_name: repo-os.qcow2
    disk_os_size: 200G
    nics:
    - name: eth0
      config: "--type bridge --source br1 --model virtio"
    ram: 1024
    vcpus: 1

rhosp_director:
  poweroff: true
  bootdev: network
  validation_errors: []
  repos:
    - rhel-7-server-rpms
    - rhel-7-server-extras-rpms
    - rhel-7-server-rh-common-rpms
    - rhel-ha-for-rhel-7-server-rpms
    - rhel-7-server-openstack-{{ versions.rhosp }}-rpms
    - rhel-7-server-satellite-tools-{{ versions.satellite }}-rpms
    - rhel-7-server-rhceph-2-osd-rpms
    - rhel-7-server-rhceph-2-mon-rpms
    - rhel-7-server-rhceph-2-tools-rpms

  # stack user gets created and will be used for all RHOSP actions on undercloud
  stack_user_pwd: "{{ vault_stack_user_pwd }}"

  # All variables for undercloud.conf
  cloud_domain: "{{ domain }}"
  hostname_short: undercloud
  ntp_servers: time.google.com #TODO: public or local NTP? maybe KVM or Cisco Switch
  # Network interface on the Undercloud that will be handling the PXE
  # boots and DHCP for Overcloud instances
  provisioning_interface: eth0
  # IP information for the interface on the Undercloud that will be
  # handling the PXE boots and DHCP for Overcloud instances.  The IP
  # portion of the value will be assigned to the network interface
  # defined by local_interface, with the netmask defined by the prefix
  # portion of the value
  provisioning_ip: 192.168.2.5/24
  # Network CIDR for the Neutron-managed network for Overcloud
  # instances. This should be the subnet used for PXE booting
  provisioning_network_cidr: 192.168.2.0/24
  # Network gateway for the Neutron-managed network for Overcloud
  # instances. This should match the local_ip above when using masquerading
  provisioning_network_gateway: 192.168.2.5
  # Virtual IP address to use for the admin endpoints of Undercloud services.
  admin_apis_vip: 192.168.2.6
  # Temporary IP range that will be given to nodes during the discovery
  # process.  Should not overlap with the range defined by dhcp_start
  # and dhcp_end, but should be in the same network
  inspection_dhcp_start: 192.168.2.20
  inspection_dhcp_end: 192.168.2.39
  # Start of DHCP allocation range for PXE and DHCP of Overcloud instances
  deploy_dhcp_start: 192.168.2.40
  # End of DHCP allocation range for PXE and DHCP of Overcloud instances
  deploy_dhcp_end: 192.168.2.69
  # Defines whether to wipe the hard drive of overcloud nodes between
  # deployments and after the introspection
  clean_nodes: false
  # Set admin password for undercloud
  admin_password: "{{ vault_undercloud_admin_pwd }}"

  overcloud_nodes:
    - name: node1
      profile: control
      pm_addr: "192.168.1.21"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node2
      profile: compute
      pm_addr: "192.168.10.22"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node3
      profile: compute
      pm_addr: "192.168.1.23"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node4
      profile: compute
      pm_addr: "192.168.1.24"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node5
      profile: compute
      pm_addr: "192.168.1.25"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node6
      profile: compute
      pm_addr: "192.168.1.26"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"
    - name: node7
      profile: compute
      pm_addr: "192.168.1.27"
      pm_user: "ADMIN"
      pm_pwd: "ADMIN"
      #NOTE: If pxe_ssh, ipmi_addr should be IP of hypervisor. If pxe_ipmitool,
      #      should be a list of IPs to check and register
      pm_driver: "pxe_ipmitool"

rhosp_overcloud:
  timezone: "US/Eastern"
  cloud_name: openstack
  operator_pub_key: "{{ vault_operator_pub_key }}"
