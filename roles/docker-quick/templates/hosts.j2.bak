# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
etcd
nodes
glusterfs

# Set variables common for all OSEv3 hosts
[OSEv3:vars]
# SSH user, this user should allow ssh based auth without requiring a password
ansible_ssh_user={{ ssh_user }}
ansible_ssh_common_args='-o StrictHostKeyChecking=no'
openshift_metrics_cassandra_nodeselector={'region': 'infra'}
openshift_metrics_hawkular_nodeselector={'region': 'infra'}
openshift_metrics_heapster_nodeselector={'region': 'infra'}
openshift_logging_es_nodeselector={'region': 'infra'}
openshift_logging_curator_nodeselector={'region': 'infra'}
openshift_logging_kibana_nodeselector={'region': 'infra'}

# If ansible_ssh_user is not root, ansible_become must be set to true
ansible_become=true

openshift_deployment_type=openshift-enterprise

# uncomment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvider
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'}]
openshift_master_identity_providers=[{'name': 'allow_all', 'login': 'true', 'challenge': 'true', 'kind': 'AllowAllPasswordIdentityProvider'}]

#openshift_master_cluster_hostname={{ hostvars[groups['master'][0]]['ansible_hostname'] }}.{{ domain }}
openshift_master_cluster_public_hostname={{ ocp_wildcard_domain }}

openshift_master_default_subdomain={{ ocp_wildcard_domain }}

# default project node selector
osm_default_node_selector='role=app'

# Enable cockpit
osm_use_cockpit=true
#
# Set cockpit plugins
osm_cockpit_plugins=['cockpit-kubernetes']

openshift_disable_check=docker_image_availability

# Configure the multi-tenant SDN plugin (default is 'redhat/openshift-ovs-subnet')
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

#Change console/api port to 443 instead of 8443
openshift_master_api_port=443
openshift_master_console_port=443

#Enable OpenShift Service Catalog
openshift_enable_service_catalog=true

# Enable template service broker (requires service catalog to be enabled, above)
template_service_broker_install=true
template_service_broker_selector={'role': 'infra'}

#CNS

#openshift_storage_glusterfs_block_deploy=true
#openshift_storage_glusterfs_block_host_vol_size=20
#openshift_storage_glusterfs_block_storageclass=true
#openshift_storage_glusterfs_block_storageclass_default=true
#openshift_storageclass_default=false

#openshift_storage_glusterfs_namespace=glusterfs
#openshift_storage_glusterfs_name=storage
openshift_storage_glusterfs_heketi_wipe=true
openshift_storage_glusterfs_wipe=true
openshift_storage_glusterfs_storageclass_default=true
#openshift_storage_glusterfs_block_storageclass=false
#openshift_master_dynamic_provisioning_enabled=true
openshift_storage_glusterfs_timeout=900
#dynamic_volumes_check=False

#Shared MPC registry
openshift_docker_additional_registries={{ ocp_shared_registry_server }}:{{ ocp_shared_registry_port }}
openshift_docker_insecure_registries={{ ocp_shared_registry_server }}:{{ ocp_shared_registry_port }}

# OpenShift Router Options
#
# An OpenShift router will be created during install if there are
# nodes present with labels matching the default router selector,
# "region=infra". Set openshift_node_labels per node as needed in
# order to label nodes.
#
# Example:
# [nodes]
# node.example.com openshift_node_labels="{'region': 'infra'}"
#
# Router selector (optional)
# Router will only be created if nodes matching this label are present.
# Default value: 'region=infra'
openshift_hosted_router_selector='role=infra'

# Openshift Registry Options
#
# An OpenShift registry will be created during install if there are
# nodes present with labels matching the default registry selector,
# "region=infra". Set openshift_node_labels per node as needed in
# order to label nodes.
#
# Example:
# [nodes]
# node.example.com openshift_node_labels="{'region': 'infra'}"
#
# Registry selector (optional)
# Registry will only be created if nodes matching this label are present.
# Default value: 'region=infra'
openshift_hosted_registry_selector='role=infra'
openshift_hosted_registry_storage_kind=glusterfs
openshift_hosted_registry_storage_volume_size={{ openshift_registry_volume_size }}Gi

# Metrics deployment
# See: https://docs.openshift.com/enterprise/latest/install_config/cluster_metrics.html
#
# By default metrics are not automatically deployed, set this to enable them
openshift_metrics_install_metrics=true
#
# Storage Options
openshift_metrics_cassandra_storage_type=dynamic
#
# Other Metrics Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_metrics/README.md
openshift_metrics_cassandra_nodeselector={'role': 'infra'}
openshift_metrics_hawkular_nodeselector={'role': 'infra'}
openshift_metrics_heapster_nodeselector={'role': 'infra'}

# Logging deployment
#
# Currently logging deployment is disabled by default, enable it by setting this
openshift_logging_install_logging=true
#
# Logging storage config
openshift_logging_es_pvc_dynamic=true
#
# Other Logging Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_logging/README.md
openshift_logging_es_nodeselector={'role': 'infra'}
openshift_logging_curator_nodeselector={'role': 'infra'}
openshift_logging_kibana_nodeselector={'role': 'infra'}

# Prometheus deployment
#
# Currently prometheus deployment is disabled by default, enable it by setting this
#openshift_hosted_prometheus_deploy=true
#
# Prometheus storage config
#openshift_prometheus_storage_type=pvc
#openshift_prometheus_storage_class=glusterfs-storage
#openshift_prometheus_alertmanager_storage_type=pvc
#openshift_prometheus_alertmanager_storage_class=glusterfs-storage
#openshift_prometheus_alertbuffer_storage_type=pvc
#openshift_prometheus_alertbuffer_storageinventory_class=glusterfs-storage
#
# Other Prometheus Options
#openshift_prometheus_node_selector={'role': 'infra'}
# The default v0.15.2 doesn't exist
#openshift_prometheus_node_exporter_image_version=v3.9

# host group for masters
[masters]
{{ hostvars[groups['master'][0]]['ansible_hostname'] }}.{{ domain }}

[etcd]
{{ hostvars[groups['master'][0]]['ansible_hostname'] }}.{{ domain }}

# host group for nodes, includes region info
[nodes]
{{ hostvars[groups['master'][0]]['ansible_hostname'] }}.{{ domain }}
{{ hostvars[groups['infra'][0]]['ansible_hostname'] }}.{{ domain }} openshift_node_labels="{'region': 'infra', 'zone': 'default', 'role': 'infra'}"
{% for host in groups['node'] %}
{{ hostvars[host].ansible_hostname }}.{{ domain }} openshift_node_labels="{'region': 'primary', 'zone': 'default', 'role': 'app'}"
{% endfor %}

# host group for glusterfs
[glusterfs]
{% set glusterfs_zone = 1 %}
{% for host in groups['node'] %}
{{ hostvars[host].ansible_hostname }}.{{ domain }} glusterfs_devices='[ "{{ cns_dev }}" ]'
#{{ hostvars[host].ansible_hostname }}.{{ domain }} glusterfs_ip={{ hostvars[host].inventory_hostname }} glusterfs_zone={{ glusterfs_zone }} glusterfs_devices='[ "{{ cns_dev }}" ]'
{% set glusterfs_zone = glusterfs_zone + 1 %}
{% endfor %}

